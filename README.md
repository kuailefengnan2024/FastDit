## åŸºäº Transformer çš„å¯æ‰©å±•æ‰©æ•£æ¨¡å‹ (DiT)<br><sub>æ”¹è¿›çš„ PyTorch å®ç°</sub>

### [è®ºæ–‡](http://arxiv.org/abs/2212.09748) | [é¡¹ç›®é¡µé¢](https://www.wpeebles.com/DiT) | è¿è¡Œ DiT-XL/2 [![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/wpeebles/DiT) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/facebookresearch/DiT/blob/main/run_DiT.ipynb) <a href="https://replicate.com/arielreplicate/scalable_diffusion_with_transformers"><img src="https://replicate.com/arielreplicate/scalable_diffusion_with_transformers/badge"></a>

![DiT æ ·æœ¬](visuals/sample_grid_0.png)

æœ¬ä»“åº“æä¾›äº†è®ºæ–‡ [**Scalable Diffusion Models with Transformers**](https://www.wpeebles.com/DiT) çš„æ”¹è¿› PyTorch å®ç°ã€‚

å®ƒåŒ…å«ï¼š

* ğŸª æ”¹è¿›çš„ PyTorch [å®ç°](models.py) å’ŒåŸå§‹ [å®ç°](train_options/models_original.py) çš„ DiT
* âš¡ï¸ åœ¨ ImageNet ä¸Šè®­ç»ƒçš„é¢„è®­ç»ƒç±»æ¡ä»¶ DiT æ¨¡å‹ (512x512 å’Œ 256x256)
* ğŸ’¥ ç”¨äºè¿è¡Œé¢„è®­ç»ƒ DiT-XL/2 æ¨¡å‹çš„ç‹¬ç«‹ [Hugging Face Space](https://huggingface.co/spaces/wpeebles/DiT) å’Œ [Colab ç¬”è®°æœ¬](http://colab.research.google.com/github/facebookresearch/DiT/blob/main/run_DiT.ipynb)
* ğŸ›¸ æ”¹è¿›çš„ DiT [è®­ç»ƒè„šæœ¬](train.py) å’Œå¤šç§ [è®­ç»ƒé€‰é¡¹](train_options)

## è®¾ç½®

é¦–å…ˆï¼Œä¸‹è½½å¹¶è®¾ç½®ä»“åº“ï¼š

```bash
git clone https://github.com/chuanyangjin/fast-DiT.git
cd DiT
```

æˆ‘ä»¬æä¾›äº†ä¸€ä¸ª [`environment.yml`](environment.yml) æ–‡ä»¶ï¼Œå¯ç”¨äºåˆ›å»º Conda ç¯å¢ƒã€‚å¦‚æœæ‚¨åªæƒ³åœ¨ CPU ä¸Šæœ¬åœ°è¿è¡Œé¢„è®­ç»ƒæ¨¡å‹ï¼Œå¯ä»¥ä»æ–‡ä»¶ä¸­åˆ é™¤ `cudatoolkit` å’Œ `pytorch-cuda` è¦æ±‚ã€‚

```bash
conda env create -f environment.yml
conda activate DiT
```


## é‡‡æ · [![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/wpeebles/DiT) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/facebookresearch/DiT/blob/main/run_DiT.ipynb)
![æ›´å¤š DiT æ ·æœ¬](visuals/sample_grid_1.png)

**é¢„è®­ç»ƒ DiT æ£€æŸ¥ç‚¹ã€‚** æ‚¨å¯ä»¥ä½¿ç”¨ [`sample.py`](sample.py) ä»æˆ‘ä»¬çš„é¢„è®­ç»ƒ DiT æ¨¡å‹ä¸­é‡‡æ ·ã€‚æ ¹æ®æ‚¨ä½¿ç”¨çš„æ¨¡å‹ï¼Œé¢„è®­ç»ƒ DiT æ¨¡å‹çš„æƒé‡å°†è‡ªåŠ¨ä¸‹è½½ã€‚è¯¥è„šæœ¬æœ‰å„ç§å‚æ•°ï¼Œå¯ä»¥åœ¨ 256x256 å’Œ 512x512 æ¨¡å‹ä¹‹é—´åˆ‡æ¢ï¼Œè°ƒæ•´é‡‡æ ·æ­¥éª¤ï¼Œæ›´æ”¹æ— åˆ†ç±»å™¨å¼•å¯¼å°ºåº¦ç­‰ã€‚ä¾‹å¦‚ï¼Œè¦ä»æˆ‘ä»¬çš„ 512x512 DiT-XL/2 æ¨¡å‹ä¸­é‡‡æ ·ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ï¼š

```bash
python sample.py --image-size 512 --seed 1
```

ä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œæ‚¨ä¹Ÿå¯ä»¥ç›´æ¥åœ¨è¿™é‡Œä¸‹è½½æˆ‘ä»¬çš„é¢„è®­ç»ƒ DiT æ¨¡å‹ï¼š

| DiT æ¨¡å‹     | å›¾åƒåˆ†è¾¨ç‡ | FID-50K | Inception Score | Gflops | 
|---------------|------------------|---------|-----------------|--------|
| [XL/2](https://dl.fbaipublicfiles.com/DiT/models/DiT-XL-2-256x256.pt) | 256x256          | 2.27    | 278.24          | 119    |
| [XL/2](https://dl.fbaipublicfiles.com/DiT/models/DiT-XL-2-512x512.pt) | 512x512          | 3.04    | 240.82          | 525    |


**è‡ªå®šä¹‰ DiT æ£€æŸ¥ç‚¹ã€‚** å¦‚æœæ‚¨ä½¿ç”¨ [`train.py`](train.py) è®­ç»ƒäº†æ–°çš„ DiT æ¨¡å‹ï¼ˆå‚è§[ä¸‹æ–‡](#è®­ç»ƒ-dit)ï¼‰ï¼Œæ‚¨å¯ä»¥æ·»åŠ  `--ckpt` å‚æ•°æ¥ä½¿ç”¨æ‚¨è‡ªå·±çš„æ£€æŸ¥ç‚¹ã€‚ä¾‹å¦‚ï¼Œè¦ä»è‡ªå®šä¹‰ 256x256 DiT-L/4 æ¨¡å‹çš„ EMA æƒé‡ä¸­é‡‡æ ·ï¼Œè¯·è¿è¡Œï¼š

```bash
python sample.py --model DiT-L/4 --image-size 256 --ckpt /path/to/model.pt
```


## è®­ç»ƒ
### è®­ç»ƒå‰å‡†å¤‡
ä½¿ç”¨ `1` ä¸ª GPU åœ¨ä¸€ä¸ªèŠ‚ç‚¹ä¸Šæå– ImageNet ç‰¹å¾ï¼š

```bash
torchrun --nnodes=1 --nproc_per_node=1 extract_features.py --model DiT-XL/2 --data-path /path/to/imagenet/train --features-path /path/to/store/features
```

### è®­ç»ƒ DiT
æˆ‘ä»¬åœ¨ [`train.py`](train.py) ä¸­æä¾›äº† DiT çš„è®­ç»ƒè„šæœ¬ã€‚æ­¤è„šæœ¬å¯ç”¨äºè®­ç»ƒç±»æ¡ä»¶ DiT æ¨¡å‹ï¼Œä½†å¯ä»¥è½»æ¾ä¿®æ”¹ä»¥æ”¯æŒå…¶ä»–ç±»å‹çš„æ¡ä»¶ã€‚

åœ¨ä¸€ä¸ªèŠ‚ç‚¹ä¸Šä½¿ç”¨ `1` ä¸ª GPU å¯åŠ¨ DiT-XL/2 (256x256) è®­ç»ƒï¼š

```bash
accelerate launch --mixed_precision fp16 train.py --model DiT-XL/2 --feature-path /path/to/store/features
```

åœ¨ä¸€ä¸ªèŠ‚ç‚¹ä¸Šä½¿ç”¨ `N` ä¸ª GPU å¯åŠ¨ DiT-XL/2 (256x256) è®­ç»ƒï¼š
```bash
accelerate launch --multi_gpu --num_processes N --mixed_precision fp16 train.py --model DiT-XL/2 --feature-path /path/to/store/features
```

æˆ–è€…ï¼Œæ‚¨å¯ä»¥é€‰æ‹©æå–å’Œè®­ç»ƒ [è®­ç»ƒé€‰é¡¹](train_options) æ–‡ä»¶å¤¹ä¸­çš„è„šæœ¬ã€‚


### PyTorch è®­ç»ƒç»“æœ

æˆ‘ä»¬ä½¿ç”¨ PyTorch è®­ç»ƒè„šæœ¬ä»å¤´å¼€å§‹è®­ç»ƒäº† DiT-XL/2 å’Œ DiT-B/4 æ¨¡å‹ï¼Œä»¥éªŒè¯å®ƒæ˜¯å¦èƒ½å¤Ÿé‡ç°åŸå§‹ JAX ç»“æœï¼Œç›´åˆ°æ•°åä¸‡æ¬¡è®­ç»ƒè¿­ä»£ã€‚åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œä¸ JAX è®­ç»ƒçš„æ¨¡å‹ç›¸æ¯”ï¼ŒPyTorch è®­ç»ƒçš„æ¨¡å‹ç»™å‡ºäº†ç›¸ä¼¼ï¼ˆæœ‰æ—¶ç•¥å¥½ï¼‰çš„ç»“æœï¼Œåœ¨åˆç†çš„éšæœºå˜åŒ–èŒƒå›´å†…ã€‚ä¸€äº›æ•°æ®ç‚¹ï¼š

| DiT æ¨¡å‹  | è®­ç»ƒæ­¥éª¤ | FID-50K<br> (JAX è®­ç»ƒ) | FID-50K<br> (PyTorch è®­ç»ƒ) | PyTorch å…¨å±€è®­ç»ƒç§å­ |
|------------|-------------|----------------------------|--------------------------------|------------------------------|
| XL/2       | 400K        | 19.5                       | **18.1**                       | 42                           |
| B/4        | 400K        | **68.4**                   | 68.9                           | 42                           |
| B/4        | 400K        | 68.4                       | **68.3**                       | 100                          |

è¿™äº›æ¨¡å‹åœ¨ 256x256 åˆ†è¾¨ç‡ä¸‹è®­ç»ƒï¼›æˆ‘ä»¬ä½¿ç”¨äº† 8 ä¸ª A100 æ¥è®­ç»ƒ XL/2ï¼Œ4 ä¸ª A100 æ¥è®­ç»ƒ B/4ã€‚è¯·æ³¨æ„ï¼Œæ­¤å¤„çš„ FID æ˜¯ä½¿ç”¨ 250 ä¸ª DDPM é‡‡æ ·æ­¥éª¤ï¼Œä½¿ç”¨ `mse` VAE è§£ç å™¨ä¸”æ²¡æœ‰å¼•å¯¼ (`cfg-scale=1`) è®¡ç®—çš„ã€‚


### æ”¹è¿›çš„è®­ç»ƒæ€§èƒ½
ä¸åŸå§‹å®ç°ç›¸æ¯”ï¼Œæˆ‘ä»¬å®ç°äº†ä¸€ç³»åˆ—è®­ç»ƒé€Ÿåº¦åŠ é€Ÿå’Œå†…å­˜èŠ‚çœåŠŸèƒ½ï¼ŒåŒ…æ‹¬æ¢¯åº¦æ£€æŸ¥ç‚¹ã€æ··åˆç²¾åº¦è®­ç»ƒå’Œé¢„æå– VAE ç‰¹å¾ï¼Œå¯¼è‡´ DiT-XL/2 çš„é€Ÿåº¦æé«˜äº† 95%ï¼Œå†…å­˜å‡å°‘äº† 60%ã€‚ä½¿ç”¨ A100 å…¨å±€æ‰¹é‡å¤§å°ä¸º 128 çš„ä¸€äº›æ•°æ®ç‚¹ï¼š
 
| æ¢¯åº¦æ£€æŸ¥ç‚¹ | æ··åˆç²¾åº¦è®­ç»ƒ | ç‰¹å¾é¢„æå– | è®­ç»ƒé€Ÿåº¦ | å†…å­˜ |
|:----------------------:|:------------------------:|:----------------------:|:--------------:|:------------:|
| âŒ                    | âŒ                       | âŒ                    | -              | å†…å­˜ä¸è¶³ |
| âœ”                     | âŒ                       | âŒ                    | 0.43 steps/sec | 44045 MB     |
| âœ”                     | âœ”                        | âŒ                    | 0.56 steps/sec | 40461 MB     |
| âœ”                     | âœ”                        | âœ”                     | 0.84 steps/sec | 27485 MB     |


## è¯„ä¼° (FID, Inception Score ç­‰)

æˆ‘ä»¬åŒ…å«äº†ä¸€ä¸ª [`sample_ddp.py`](sample_ddp.py) è„šæœ¬ï¼Œå¯ä»¥å¹¶è¡Œåœ°ä» DiT æ¨¡å‹ä¸­é‡‡æ ·å¤§é‡å›¾åƒã€‚è¿™ä¸ªè„šæœ¬ç”Ÿæˆä¸€ä¸ªæ ·æœ¬æ–‡ä»¶å¤¹ä»¥åŠä¸€ä¸ª `.npz` æ–‡ä»¶ï¼Œå¯ä»¥ç›´æ¥ä¸ [ADM çš„ TensorFlow è¯„ä¼°å¥—ä»¶](https://github.com/openai/guided-diffusion/tree/main/evaluations) ä¸€èµ·ä½¿ç”¨ï¼Œä»¥è®¡ç®— FIDã€Inception Score å’Œå…¶ä»–æŒ‡æ ‡ã€‚ä¾‹å¦‚ï¼Œè¦åœ¨ `N` ä¸ª GPU ä¸Šä»æˆ‘ä»¬é¢„è®­ç»ƒçš„ DiT-XL/2 æ¨¡å‹ä¸­é‡‡æ · 50K å›¾åƒï¼Œè¯·è¿è¡Œï¼š

```bash
torchrun --nnodes=1 --nproc_per_node=N sample_ddp.py --model DiT-XL/2 --num-fid-samples 50000
```

è¿˜æœ‰å‡ ä¸ªé¢å¤–çš„é€‰é¡¹ï¼›è¯¦æƒ…è¯·å‚è§ [`sample_ddp.py`](sample_ddp.py)ã€‚


## å¼•ç”¨

```bibtex
@misc{jin2024fast,
    title={Fast-DiT: Fast Diffusion Models with Transformers},
    author={Jin, Chuanyang and Xie, Saining},
    howpublished = {\url{https://github.com/chuanyangjin/fast-DiT}},
    year={2024}
}
```
